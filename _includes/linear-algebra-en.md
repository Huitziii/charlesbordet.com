This article belongs to the series **Linear Algebra for Data Science**, divided into 18 parts. To access the other articles, use the following table of contents:

* Part 0: Why using linear algebra for Data Science?
* Part 1: The three definitions of a vector
* Part 2: Linear combinations, span, and basis
* Part 3: Linear transformations and matrices
* Part 4: Matrix multiplication
* Part 5: Determinant
* Part 6: Images, kernel, and inverses
* Part 7: Rectangular matrices
* Part 8: Special matrices
* Part 9: Scalar product and duality
* Part 10: Vectorial product
* Part 11: Change of basis
* Part 12: Eigenvectors and eigenvalues
* Part 13: Singular-value decomposition (SVD)
* Part 14: Norms
* Part 15: Moore-Penrose pseudo inverse
* Part 16: Trace
* Part 17: Principal Component Analysis

---