Cet article fait partie de la série **L'algèbre linéaire pour la Data Science**, divisée en 18 parties. Pour accéder aux autres parties, utilisez le sommaire ci-dessous :

* Partie 0 : Pourquoi l'algèbre linéaire pour la Data Science ?
* Partie 1 : Les trois définitions d'un vecteur
* Partie 2 : Combinaisons linéaires, espaces engendrés, et bases
* Partie 3 : Transformations linéaires et matrices
* Partie 4 : Multiplication matricielle
* Partie 5 : Le déterminant
* Partie 6 : Images, noyaux, inverses
* Partie 7 : Matrices rectangulaires
* Partie 8 : Matrices spéciales
* Partie 9 : Produit scalaire et dualité
* Partie 10 : Produit vectoriel
* Partie 11 : Changement de base
* Partie 12 : Vecteurs propres et valeurs propres
* Partie 13 : Décomposition en valeurs singulières (SVD)
* Partie 14 : Les normes
* Partie 15 : Pseudo-inverse de Moore-Penrose
* Partie 16 : La trace
* Partie 17 : Analyse en Composante Principale (PCA)

---